# Document QA System

[Visit the App] : 

This web application provides a platform for performing Question Answering (QA) on a user-provided documents. Users can upload multiple PDF files, paste raw text, ask a question, and receive answers generated by a suite of different Natural Language Processing (NLP) techniques. The system is designed to compare the results from classical methods (TF-IDF, Bag of Words) and Transformer-based models.

## Features

-   **Multi-Document Support**: Upload multiple PDF files simultaneously.
-   **Direct Text Input**: Paste text directly into a textarea for analysis.
-   **Multiple NLP Techniques**:
    -   TF-IDF
    -   Bag of Words (BoW)
    -   Word Embeddings (GloVe)
    -   Transformer Model (Tiny Roberta)
-   **Comparison View**: Select and compare answers from different techniques side-by-side.

<!-- ### Performance: Minimizing Model Load Times in Production -->

<!-- Large NLP models can have long startup times, which is detrimental in a production environment. This application employs several strategies to ensure fast, efficient model loading:

1.  **On-Startup Loading & In-Memory Caching**:
    -   All heavy models (Gensim word embeddings and Hugging Face Transformers) are loaded **once** when the Flask application starts, not per-request.
    -   The loaded models are stored in a global cache (`word_embedding_model_cache`, `qa_pipeline_cache`). Subsequent calls to the loading functions retrieve the model from memory instantly, avoiding redundant processing.

2.  **Gunicorn Preloading**:
    -   The `Procfile` is configured with `gunicorn --preload`.
    -   This directive instructs Gunicorn to load the entire application, including the NLP models, into the master process *before* forking individual worker processes.
    -   **Benefit**: This leverages the "Copy-on-Write" memory optimization. All worker processes share the same initial memory footprint of the loaded models, significantly reducing the total RAM consumption of the application.
 -->

## Project Structure
```

/qa-app
|-- app.py                 # Main Flask application, handles routing
|-- utils.py                # Utility functions (PDF extraction, text cleaning)
|-- requirements.txt        # Python dependencies
|-- Procfile                # Deployment configuration for Render/Heroku
|-- /techniques             # Python package for all NLP methods      
|   |-- classical.py        # Logic for TF-IDF, BoW, Word Embeddings
|   |-- transformer.py      # Logic for Transformer-based QA (DistilBERT)
|-- /templates              # HTML files
|   |-- index.html          # Main page with the form
|   |-- results.html        # Page to display the results
|-- /static                 # CSS, JS, and other static assets
|   |-- /css
|       |-- style.css       # Stylesheet for the application
```

<!-- ## Setup and Local Development

**Prerequisites**:
-   Python 3.8+
-   `pip` and `venv`

**Instructions**:

1.  **Clone the repository**:
    ```bash
    git clone https://github.com/santoshkkashyap25/AskMyPDF.git
    cd AskMyPDF
    ```

2.  **Create and activate a virtual environment**:
    ```bash
    # For macOS/Linux
    python3 -m venv venv
    source venv/bin/activate

    # For Windows
    python -m venv env
    env\Scripts\activate
    ```

3.  **Install the dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

4.  **Run the Flask application**:
    ```bash
    python app.py
    ```
    -   The first time you run the app, it will download the necessary NLP models. This might take a few minutes. Subsequent launches will be fast.

5.  Open your browser and navigate to `http://127.0.0.1:5000`.


 -->
 ## Other Works

[Visit the App] : https://transnlp.streamlit.app/
